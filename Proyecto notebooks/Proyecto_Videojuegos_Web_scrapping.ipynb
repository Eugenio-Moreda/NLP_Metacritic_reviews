{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analisis y clasificación de las reviews y comentarios en el sector de los videojuegos**\n",
    "## **WEB SCRAPPING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eugenio Alberto Moreda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import sleep, strftime\n",
    "import random\n",
    "from random import randint\n",
    "import shutil\n",
    "import pickle\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web Scrapping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usuarios = pd.DataFrame(columns = [\n",
    "'Titulo', 'Plataforma', 'Fecha_salida', \n",
    "            'Puntuacion_usuarios',\n",
    "            'Numero_criticas_usuarios_positivas',\n",
    "            'Numero_criticas_usuarios_mixtas' ,\n",
    "            'Numero_criticas_usuarios_negativas',\n",
    "            'Puntuaciones_usuarios'  ,\n",
    "            'Usuarios' ,\n",
    "            'Fecha_review_usuarios',\n",
    "            'Reviews_usarios' ,\n",
    "            'Usuarios_ayudados' ,\n",
    "            'Usuarios_ayudados_total' \n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciar el navegador y obtener los enlaces que necesitamos para hacer el web scrapping. En este caso se muestran para obtneer los enlaces de los comentarios de usuarios en ps4, pero se podría ajustar a los que se buscase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver = r\"C:\\Users\\Eugenio\\Documents\\Bootcamp data science\\chromedriver\"\n",
    "navegador = webdriver.Chrome(executable_path = chrome_driver)\n",
    "user_urls=[]\n",
    "for i in range (20):\n",
    "    navegador.get('https://www.metacritic.com/browse/games/score/metascore/all/ps4/filtered?page='+str(i))\n",
    "    source = navegador.page_source\n",
    "    soup = BeautifulSoup(source)\n",
    "    for item in soup.find_all('div', class_='clamp-userscore'):\n",
    "        for link in item.find_all('a'):\n",
    "            user_urls.append(link.get('href'))\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables recordatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "videojuego_user=0\n",
    "lista_repetir_final=0\n",
    "errores_comentario=[]\n",
    "primera=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio navegador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_driver = r\"C:\\Users\\Eugenio\\Documents\\Bootcamp data science\\chromedriver\"\n",
    "navegador = webdriver.Chrome(executable_path = chrome_driver)\n",
    "\n",
    "navegador.get('https://www.metacritic.com') \n",
    "sleep(2)\n",
    "navegador.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es este caso se muestra para extraer los comentarios de usuarios, pero podría hacer igualmente para las reseñas de medios cambiando los enlaces que se le proporciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        try:\n",
    "            navegador.find_element_by_xpath('//*[@id=\"onetrust-accept-btn-handler\"]').click()\n",
    "        except:\n",
    "            pass \n",
    "        for p, url_user in enumerate (user_urls[lista_repetir[videojuego_user]:], videojuego_user):\n",
    "            videojuego_user= p\n",
    "            \n",
    "            navegador.get('https://www.metacritic.com'+str(url_user))\n",
    "            sleep(randint(3,5))\n",
    "            source = navegador.page_source\n",
    "            soup = BeautifulSoup(source)     \n",
    "            \n",
    "            user_scores=[]\n",
    "            users=[]\n",
    "            date_user_score=[]\n",
    "            user_reviews=[]\n",
    "            ayudados=[]\n",
    "            total_ayudados=[]\n",
    "            \n",
    "            titulo=soup.find('div', class_='product_title').text.strip().split('\\n')[0].strip()\n",
    "            plataforma=soup.find('div', class_='product_title').text.strip().split('\\n')[-1].strip()\n",
    "            try:\n",
    "                fecha_salida=soup.find('li', class_='summary_detail release_data').find('span', class_=\"data\").text\n",
    "            except:\n",
    "                fecha_salida= np.nan\n",
    "            try:\n",
    "                user_score=soup.find('div', class_=\"metascore_w user large game positive\").text\n",
    "            except:\n",
    "                try:\n",
    "                    user_score=soup.find('div', class_=\"metascore_w user large game mixed\").text\n",
    "                except:\n",
    "                    try:\n",
    "                        user_score=soup.find('div', class_=\"metascore_w user large game negative\").text\n",
    "                    except:\n",
    "                        user_score=np.nan\n",
    "            try:    \n",
    "                numer_user_score_positive = soup.find('div', class_='score_distribution').find_all('span', class_='count')[0].text\n",
    "                numer_user_score_mixed = soup.find('div', class_='score_distribution').find_all('span', class_='count')[1].text\n",
    "                numer_user_score_negative = soup.find('div', class_='score_distribution').find_all('span', class_='count')[2].text\n",
    "            except:\n",
    "                numer_user_score_positive = np.nan\n",
    "                numer_user_score_mixed = np.nan\n",
    "                numer_user_score_negative = np.nan\n",
    "                                \n",
    "            try:\n",
    "                ultima_pagina=int(soup.find('li', class_='page last_page').find('a', class_='page_num').text)\n",
    "            except:\n",
    "                try:\n",
    "                    ultima_pagina=int(soup.find('li', class_='page last_page active_page').find('a', class_='page_num').text)\n",
    "                except:\n",
    "                    ultima_pagina=1\n",
    "                    \n",
    "            for pri, paginas in enumerate (range (primera,ultima_pagina), primera):\n",
    "                primera=pri\n",
    "                navegador.get('https://www.metacritic.com'+str(url_user)+'?page='+str(paginas))\n",
    "                sleep(randint(3,5))\n",
    "                source = navegador.page_source\n",
    "                soup = BeautifulSoup(source)\n",
    "                try:\n",
    "                    soup.find('div', class_='msg msg_no_reviews')\n",
    "                    user_scores=np.nan\n",
    "                    users=np.nan\n",
    "                    date_user_score=np.nan\n",
    "                    user_reviews=np.nan\n",
    "                    ayudados=np.nan\n",
    "                    total_ayudados=np.nan \n",
    "                except:\n",
    "                    numero_criticas_usuarios_actual = len(soup.find('ol', class_=\"reviews user_reviews\").find_all('div', class_=\"review_grade\"))\n",
    "                    if numero_criticas_usuarios_actual== 1:\n",
    "                        user_scores.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('div', class_='review_grade').text.split('\\n')[1])\n",
    "                        users.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('div', class_='name').text.split('\\n')[1])\n",
    "                        date_user_score.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('div', class_='date').text)\n",
    "                        try:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('div', class_='review_body').find('span', class_='blurb blurb_expanded').text)                        \n",
    "                        except:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('div', class_='review_body').text.split('\\n')[1].strip())\n",
    "                        ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('span', class_='total_ups').text)\n",
    "                        total_ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review last_review').find('span', class_='total_thumbs').text)\n",
    "                    elif numero_criticas_usuarios_actual== 2:\n",
    "                        user_scores.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='review_grade').text.split('\\n')[1])\n",
    "                        users.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='name').text.split('\\n')[1])\n",
    "                        date_user_score.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='date').text)\n",
    "                        try:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='review_body').find('span', class_='blurb blurb_expanded').text)\n",
    "                        except:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='review_body').text.split('\\n')[1].strip())\n",
    "                        ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('span', class_='total_ups').text)\n",
    "                        total_ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('span', class_='total_thumbs').text) \n",
    "                        user_scores.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='review_grade').text.split('\\n')[1])\n",
    "                        users.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='name').text.split('\\n')[1])\n",
    "                        date_user_score.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='date').text)\n",
    "                        try:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='review_body').find('span', class_='blurb blurb_expanded').text)                            \n",
    "                        except: \n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='review_body').text.split('\\n')[1].strip())\n",
    "                        ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('span', class_='total_ups').text)\n",
    "                        total_ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('span', class_='total_thumbs').text)       \n",
    "                    else:\n",
    "                        user_scores.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='review_grade').text.split('\\n')[1])\n",
    "                        users.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='name').text.split('\\n')[1])\n",
    "                        date_user_score.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='date').text)\n",
    "                        try:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='review_body').find('span', class_='blurb blurb_expanded').text)\n",
    "                        except:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('div', class_='review_body').text.split('\\n')[1].strip())\n",
    "                        ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('span', class_='total_ups').text)\n",
    "                        total_ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review first_review').find('span', class_='total_thumbs').text)\n",
    "                        try:  \n",
    "                            for i in range (len(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review'))):\n",
    "                                user_scores.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('div', class_='review_grade').text.split('\\n')[1])\n",
    "                                users.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('div', class_='name').text.split('\\n')[1])\n",
    "                                date_user_score.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('div', class_='date').text)\n",
    "                                try:\n",
    "                                     user_reviews.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('div', class_='review_body').find('span', class_='blurb blurb_expanded').text)\n",
    "                                except:\n",
    "                                    user_reviews.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('div', class_='review_body').text.split('\\n')[1].strip())\n",
    "                                ayudados.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('span', class_='total_ups').text)\n",
    "                                total_ayudados.append(soup.find('ol', class_='reviews user_reviews').find_all('li', class_='review user_review')[i].find('span', class_='total_thumbs').text)\n",
    "                        except:\n",
    "                            pass                    \n",
    "                        user_scores.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='review_grade').text.split('\\n')[1])\n",
    "                        users.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='name').text.split('\\n')[1])\n",
    "                        date_user_score.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='date').text)\n",
    "                        try:\n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='review_body').find('span', class_='blurb blurb_expanded').text)                            \n",
    "                        except: \n",
    "                            user_reviews.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('div', class_='review_body').text.split('\\n')[1].strip())\n",
    "                        ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('span', class_='total_ups').text)\n",
    "                        total_ayudados.append(soup.find('ol', class_='reviews user_reviews').find('li', class_='review user_review last_review').find('span', class_='total_thumbs').text)                                       \n",
    "                sleep(randint(3,5))                              \n",
    "            \n",
    "            new_row = {\n",
    "                    'Titulo' : titulo,\n",
    "                    'Plataforma' : plataforma,\n",
    "                    'Fecha_salida' : fecha_salida,\n",
    "                    'Puntuacion_usuarios' : user_score,\n",
    "                    'Numero_criticas_usuarios_positivas' :  numer_user_score_positive,\n",
    "                    'Numero_criticas_usuarios_mixtas'    :  numer_user_score_mixed,\n",
    "                    'Numero_criticas_usuarios_negativas' :  numer_user_score_negative,\n",
    "                    'Puntuaciones_usuarios'   :  user_scores,\n",
    "                    'Usuarios'                :  users,\n",
    "                    'Fecha_review_usuarios'   :  date_user_score,\n",
    "                    'Reviews_usarios'         :  user_reviews,\n",
    "                    'Usuarios_ayudados'       :  ayudados,\n",
    "                    'Usuarios_ayudados_total' : total_ayudados     \n",
    "                 }\n",
    "            df_usuarios = df_usuarios.append(new_row, ignore_index=True)\n",
    "            primera=0\n",
    "        sleep(randint(4,7))\n",
    "        break\n",
    "    except:\n",
    "        navegador.refresh()\n",
    "        errores_comentario.append(titulo)\n",
    "        continue   \n",
    "    break\n",
    "df_usuarios.to_pickle('/Users/Eugenio/Documents/comentarios_presentacion.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
